{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown --id 1If5gkWEfChJHc8v8CCEhGhEeeAqsxKTz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed19560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from pnpflow.models import UNet\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# define small pretrained unet\n",
    "\n",
    "net = UNet(\n",
    "    input_channels=1,\n",
    "    input_height=28,\n",
    "    ch=32,\n",
    "    ch_mult=(1, 2),\n",
    "    num_res_blocks=2,\n",
    "    attn_resolutions=(16,),\n",
    "    resamp_with_conv=True,\n",
    ").to(device)\n",
    "\n",
    "net.load_state_dict(\n",
    "    torch.load('model_final_mnist_dirichlet.pt', \n",
    "               map_location=torch.device(device)))\n",
    "net.eval()\n",
    "\n",
    "# load testset and define latent distribution\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "diri = torch.distributions.Dirichlet(torch.ones(784))\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "def upsample(x, sf=4):\n",
    "    '''s-fold upsampler\n",
    "\n",
    "    Upsampling the spatial size by filling the new entries with zeros\n",
    "\n",
    "    x: tensor image, NxCxWxH\n",
    "    '''\n",
    "    st = 0\n",
    "    z = torch.zeros(\n",
    "        (x.shape[0],\n",
    "         x.shape[1],\n",
    "         x.shape[2] *\n",
    "         sf,\n",
    "         x.shape[3] *\n",
    "         sf)).type_as(x)\n",
    "    z[..., st::sf, st::sf].copy_(x)\n",
    "    return z\n",
    "\n",
    "def upsample_bicubic(x, sf=2):\n",
    "    '''s-fold upsampler\n",
    "\n",
    "    Upsampling the spatial size by filling the new entries with zeros\n",
    "\n",
    "    x: tensor image, NxCxWxH\n",
    "    '''\n",
    "    st = 0\n",
    "    z = torch.zeros(\n",
    "        (x.shape[0],\n",
    "         x.shape[1],\n",
    "         x.shape[2] *\n",
    "         sf,\n",
    "         x.shape[3] *\n",
    "         sf)).type_as(x)\n",
    "    z[..., st::sf, st::sf].copy_(x)\n",
    "    z = F.interpolate(z, scale_factor=sf, mode='bicubic')\n",
    "    return z\n",
    "\n",
    "\n",
    "def downsample(x, sf=2):\n",
    "    '''s-fold downsampler\n",
    "\n",
    "    Keeping the upper-left pixel for each distinct sfxsf patch and discarding the others\n",
    "\n",
    "    x: tensor image, NxCxWxH\n",
    "    '''\n",
    "    st = 0\n",
    "    return x[..., st::sf, st::sf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15024c27-687c-4635-bd78-3c0f0a507409",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Superresolution Experiment\n",
    "\n",
    "# load batch and normalize it to the simplex\n",
    "torch.manual_seed(0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "batch,y  = next(iter(testloader))\n",
    "batch = batch.to(device)\n",
    "batch = batch/torch.sum(batch, dim = (1,2,3)).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "\n",
    "batch_y = batch.clone().to(device)\n",
    "batch_y = downsample(batch_y, sf = 2) + torch.randn_like(downsample(batch_y, sf = 2))*0.0001\n",
    "\n",
    "x = diri.sample([16]).to(device)\n",
    "x = x.view(16,1,28,28)\n",
    "\n",
    "steps = 300\n",
    "num_samples = 5\n",
    "\n",
    "for k in range(steps):\n",
    "    t = k/steps\n",
    "    time = torch.tensor(t).to(device)\n",
    "    x.requires_grad_()\n",
    "    datafit = torch.sum((downsample(x, sf = 2)-batch_y)**2)*0.5\n",
    "    grad = torch.autograd.grad(datafit, x)[0]\n",
    "    x = x.detach()\n",
    "    z = x - ((1-t))*grad\n",
    "    x_new = 0\n",
    "    for _ in range(num_samples):\n",
    "        z2 = diri.sample([x.shape[0]]).to(device)\n",
    "        z2 = z2.view(x.shape[0],1,28,28)\n",
    "        z_new = t*z+(1-t)*z2\n",
    "        x_new += z_new + (1-t)*net(z_new,time.repeat(x.shape[0]))\n",
    "    x = x_new/num_samples\n",
    "\n",
    "print(torch.sum(x, dim = (1,2,3)))\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(x.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"reco.png\")\n",
    "plt.show()\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(batch.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"groundtruth.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(upsample(batch_y, sf = 2).cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"measurements.png\")\n",
    "plt.show()\n",
    "\n",
    "print(torch.sum((batch-x)**2)/len(batch))\n",
    "print(torch.sum((batch-upsample(batch_y, sf = 2))**2)/len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2f0e1-f6e5-491a-bfa2-bdf73524bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Denoising Experiment\n",
    "\n",
    "batch_y = batch.clone().to(device)\n",
    "torch.manual_seed(1)\n",
    "batch_y = batch_y+ torch.randn_like(batch_y)*0.001\n",
    "\n",
    "x = diri.sample([16]).to(device)\n",
    "x = x.view(16,1,28,28)\n",
    "\n",
    "steps = 300\n",
    "num_samples = 5\n",
    "\n",
    "for k in range(steps):\n",
    "    t = k/steps\n",
    "    time = torch.tensor(t).to(device)\n",
    "    x.requires_grad_()\n",
    "    datafit = torch.sum((x-batch_y)**2)*0.5\n",
    "    grad = torch.autograd.grad(datafit, x)[0]\n",
    "    x = x.detach()\n",
    "    z = x - ((1-t))*grad\n",
    "    x_new = 0\n",
    "    for _ in range(num_samples):\n",
    "        z2 = diri.sample([x.shape[0]]).to(device)\n",
    "        z2 = z2.view(x.shape[0],1,28,28)\n",
    "        z_new = t*z+(1-t)*z2\n",
    "        x_new += z_new + (1-t)*net(z_new,time.repeat(x.shape[0]))\n",
    "    x = x_new/num_samples\n",
    "\n",
    "print(torch.sum(x, dim = (1,2,3)))\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(x.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"reco_den.png\")\n",
    "plt.show()\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(batch.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"groundtruth_den.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(batch_y.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"measurements_den.png\")\n",
    "plt.show()\n",
    "\n",
    "print(torch.sum((batch-x)**2)/len(batch))\n",
    "print(torch.sum((batch-batch_y)**2)/len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inpainting Experiment\n",
    "\n",
    "batch_y = batch.clone().to(device)\n",
    "torch.manual_seed(2)\n",
    "batch_y = batch_y[:,:,:14,:] + torch.randn_like(batch_y[:,:,:14,:])*0.0001\n",
    "\n",
    "x = diri.sample([16]).to(device)\n",
    "x = x.view(16,1,28,28)\n",
    "\n",
    "steps = 300\n",
    "num_samples = 5\n",
    "\n",
    "for k in range(steps):\n",
    "    t = k/steps\n",
    "    time = torch.tensor(t).to(device)\n",
    "    x.requires_grad_()\n",
    "    datafit = torch.sum((x[:,:,:14,:]-batch_y)**2)*0.5\n",
    "    grad = torch.autograd.grad(datafit, x)[0]\n",
    "    x = x.detach()\n",
    "    z = x - ((1-t))*grad\n",
    "    x_new = 0\n",
    "    for _ in range(num_samples):\n",
    "        z2 = diri.sample([x.shape[0]]).to(device)\n",
    "        z2 = z2.view(x.shape[0],1,28,28)\n",
    "        z_new = t*z+(1-t)*z2\n",
    "        x_new += z_new + (1-t)*net(z_new,time.repeat(x.shape[0]))\n",
    "    x = x_new/num_samples\n",
    "\n",
    "print(torch.sum(x, dim = (1,2,3)))\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(x.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"reco_inp.png\")\n",
    "plt.show()\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(batch.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"groundtruth_inp.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(torch.cat((batch_y, torch.zeros_like(batch_y)),2).cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"measurements_inp.png\")\n",
    "plt.show()\n",
    "\n",
    "print(torch.sum((batch-x)**2)/len(batch))\n",
    "print(torch.sum((batch-torch.cat((batch_y,torch.zeros_like(batch_y)),2))**2)/len(batch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
