{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b49ee3-17c8-4f7f-b568-2b63738c9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown --id 1If5gkWEfChJHc8v8CCEhGhEeeAqsxKTz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed19560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from tqdm import tqdm \n",
    "from pnpflows.models import UNet\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# define small pretrained unet\n",
    "\n",
    "net = UNet(\n",
    "    input_channels=1,\n",
    "    input_height=28,\n",
    "    ch=32,\n",
    "    ch_mult=(1, 2),\n",
    "    num_res_blocks=2,\n",
    "    attn_resolutions=(16,),\n",
    "    resamp_with_conv=True,\n",
    ").to(device)\n",
    "\n",
    "net.load_state_dict(torch.load('model_final_mnist_dirichlet.pt'))\n",
    "net.eval()\n",
    "\n",
    "# load testset and define latent distribution\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "diri = torch.distributions.Dirichlet(torch.ones(784))\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "def upsample(x, sf=2):\n",
    "    '''s-fold upsampler\n",
    "\n",
    "    Upsampling the spatial size by filling the new entries with zeros\n",
    "\n",
    "    x: tensor image, NxCxWxH\n",
    "    '''\n",
    "    st = 0\n",
    "    z = torch.zeros(\n",
    "        (x.shape[0],\n",
    "         x.shape[1],\n",
    "         x.shape[2] *\n",
    "         sf,\n",
    "         x.shape[3] *\n",
    "         sf)).type_as(x)\n",
    "    z[..., st::sf, st::sf].copy_(x)\n",
    "    return z\n",
    "\n",
    "def downsample(x, sf=2):\n",
    "    '''s-fold downsampler\n",
    "\n",
    "    Keeping the upper-left pixel for each distinct sfxsf patch and discarding the others\n",
    "\n",
    "    x: tensor image, NxCxWxH\n",
    "    '''\n",
    "    st = 0\n",
    "    return x[..., st::sf, st::sf]\n",
    "\n",
    "\n",
    "class cnf(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def model_forward(self, x, t):\n",
    "        return self.model(x, t)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        with torch.no_grad():\n",
    "            z = self.model_forward(x, t.repeat(x.shape[0]))\n",
    "        return z\n",
    "\n",
    "cont_nf = cnf(net)\n",
    "\n",
    "# routines for d flow\n",
    "def forward_flow_matching(net, z):\n",
    "    steps = 6\n",
    "    delta = 1 / (steps - 1)\n",
    "    for i in range(steps - 1):\n",
    "        t1 = torch.ones(len(z), device=device) * delta * i\n",
    "        z = z + delta * net(z + (delta / 2)* net(z, t1), t1 + delta / 2)\n",
    "    return z\n",
    "\n",
    "\n",
    "def inverse_flow_matching(cnf, z):\n",
    "    z_t = odeint(cnf, z,\n",
    "                 torch.tensor([1.0, 0.0]).to(device),\n",
    "                 atol=1e-5,\n",
    "                 rtol=1e-5,\n",
    "                 method='dopri5',\n",
    "                 )\n",
    "    x = z_t[-1].detach()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b809e-95d8-49a5-ae6b-d9ff700ec09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Superresolution Experiment\n",
    "\n",
    "# load batch and normalize it to the simplex\n",
    "torch.manual_seed(0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "batch,y  = next(iter(testloader))\n",
    "batch = batch.to(device)\n",
    "batch = batch/torch.sum(batch, dim = (1,2,3)).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "\n",
    "batch_y = batch.clone().to(device)\n",
    "batch_y = downsample(batch_y) + torch.randn_like(downsample(batch_y))*0.0001\n",
    "\n",
    "steps = 20\n",
    "x = batch_y.clone().to(device)\n",
    "x = upsample(x)\n",
    "\n",
    "z = inverse_flow_matching(cont_nf, x).to(device)\n",
    "z = np.sqrt(0.1) * z + np.sqrt(1 -0.1) * diri.sample([16]).view(16,1,28,28).to(device)\n",
    "z = z.detach().requires_grad_(True)\n",
    "\n",
    "# start the gradient descent\n",
    "optim_img = torch.optim.LBFGS(\n",
    "    [z], max_iter=20, history_size=100, line_search_fn='strong_wolfe')\n",
    "d = z.shape[1] * z.shape[2] * z.shape[3]\n",
    "\n",
    "tq = tqdm(range(steps))\n",
    "for iteration in tq:\n",
    "\n",
    "    def closure():\n",
    "        optim_img.zero_grad()  # Reset gradients\n",
    "        reg = (torch.sum(z, dim = (1,2,3)) - torch.ones(z.shape[0], device = device))**2\n",
    "        loss = (torch.sum((downsample(forward_flow_matching(net, z))-\n",
    "                batch_y)**2, dim=(1, 2, 3))).mean() + 1000*reg.mean()\n",
    "        loss.backward()  # Compute gradients\n",
    "        return loss\n",
    "\n",
    "    optim_img.step(closure)\n",
    "\n",
    "z = z.detach().requires_grad_(False)\n",
    "restored_img = forward_flow_matching(net, z.detach())\n",
    "\n",
    "print(torch.sum(restored_img, dim = (1,2,3)))\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(restored_img.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"Dreco.png\")\n",
    "plt.show()\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(batch.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(x.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(torch.sum((batch-restored_img)**2)/len(batch))\n",
    "print(torch.sum((batch-upsample(batch_y))**2)/len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising Experiment\n",
    "\n",
    "batch_y = batch.clone().to(device)\n",
    "torch.manual_seed(1)\n",
    "batch_y = batch_y + torch.randn_like(batch_y)*0.001\n",
    "\n",
    "steps = 20\n",
    "x = batch_y.clone().to(device)\n",
    "\n",
    "z = inverse_flow_matching(cont_nf, x).to(device)\n",
    "z = np.sqrt(0.1) * z + np.sqrt(1 - 0.1) * diri.sample([16]).view(16,1,28,28).to(device)\n",
    "z = z.detach().requires_grad_(True)\n",
    "\n",
    "# start the gradient descent\n",
    "optim_img = torch.optim.LBFGS(\n",
    "    [z], max_iter=20, history_size=100, line_search_fn='strong_wolfe')\n",
    "d = z.shape[1] * z.shape[2] * z.shape[3]\n",
    "\n",
    "tq = tqdm(range(steps))\n",
    "for iteration in tq:\n",
    "\n",
    "    def closure():\n",
    "        optim_img.zero_grad()  # Reset gradients\n",
    "        reg = (torch.sum(z, dim = (1,2,3)) - torch.ones(z.shape[0], device = device))**2\n",
    "        loss = (torch.sum((forward_flow_matching(net, z) -\n",
    "                batch_y)**2, dim=(1, 2, 3))).mean() + 10000*reg.mean()\n",
    "        loss.backward()  # Compute gradients\n",
    "        return loss\n",
    "\n",
    "    optim_img.step(closure)\n",
    "\n",
    "z = z.detach().requires_grad_(False)\n",
    "restored_img = forward_flow_matching(net, z.detach())\n",
    "\n",
    "print(torch.sum(restored_img, dim = (1,2,3)))\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(restored_img.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"Dreco_den.png\",bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(batch.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(batch_y.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(torch.sum((batch-restored_img)**2)/len(batch))\n",
    "print(torch.sum((batch-batch_y)**2)/len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2f0e1-f6e5-491a-bfa2-bdf73524bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inpainting Experiment\n",
    "\n",
    "batch_y = batch.clone().to(device)\n",
    "torch.manual_seed(2)\n",
    "batch_y = batch_y[:,:,:14,:] + torch.randn_like(batch_y[:,:,:14,:])*0.0001\n",
    "\n",
    "steps = 20\n",
    "x = batch_y.clone().to(device)\n",
    "x = torch.cat((x, torch.zeros_like(x)),2)\n",
    "\n",
    "z = inverse_flow_matching(cont_nf, x).to(device)\n",
    "z = np.sqrt(0.1) * z + np.sqrt(1 - 0.1) * diri.sample([16]).view(16,1,28,28).to(device)\n",
    "z = z.detach().requires_grad_(True)\n",
    "\n",
    "# start the gradient descent\n",
    "optim_img = torch.optim.LBFGS(\n",
    "    [z], max_iter=20, history_size=100, line_search_fn='strong_wolfe')\n",
    "d = z.shape[1] * z.shape[2] * z.shape[3]\n",
    "\n",
    "tq = tqdm(range(steps))\n",
    "for iteration in tq:\n",
    "\n",
    "    def closure():\n",
    "        optim_img.zero_grad()  # Reset gradients\n",
    "        reg = (torch.sum(z, dim = (1,2,3)) - torch.ones(z.shape[0], device = device))**2\n",
    "        loss = (torch.sum((forward_flow_matching(net, z)[:,:,:14,:] -\n",
    "                batch_y)**2, dim=(1, 2, 3))).mean() + 100*reg.mean()\n",
    "        loss.backward()  # Compute gradients\n",
    "        return loss\n",
    "\n",
    "    optim_img.step(closure)\n",
    "\n",
    "z = z.detach().requires_grad_(False)\n",
    "restored_img = forward_flow_matching(net, z.detach())\n",
    "\n",
    "print(torch.sum(restored_img, dim = (1,2,3)))\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(restored_img.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"Dreco_inp.png\")\n",
    "plt.show()\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(batch.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(4,4, figsize = (4,4))\n",
    "for k in range(4):\n",
    "    for l in range(4):\n",
    "        axarr[k,l].imshow(x.cpu().data.numpy()[k*4+l].reshape(28,28), cmap = 'gray')\n",
    "        axarr[k,l].get_yaxis().set_ticks([])\n",
    "        axarr[k,l].get_xaxis().set_ticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(torch.sum((batch-restored_img)**2)/len(batch))\n",
    "print(torch.sum((batch-torch.cat((batch_y, torch.zeros_like(batch_y)),2))**2)/len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f55d5-750f-44a2-9631-512e42cd18ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
